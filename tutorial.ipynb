{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982df2be-02ee-4f2c-9af5-9fcdd706c9cf",
   "metadata": {},
   "source": [
    "# Yatai "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8be2c1-1060-41b4-aea4-1ae22794387c",
   "metadata": {},
   "source": [
    "Yatai est un outil qui permet de déployer et opérer des services de Machine Learning sur Kubernetes. \n",
    "Il est composé de quatre composants:\n",
    "- Yatai UI: Une interface utilisateur qui permet de gérer et créer les déploiements ainsi que les modèles.\n",
    "- Yatai image builder: elle crée des images docker pour les APIs\n",
    "- Yatai deployment: opérateur qui contrôle les déploiements\n",
    "- bentoml: un package python qui offre une CLI et une librairie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c88811-a32f-4d99-8a0d-4569e9303496",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bentoml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74d7fa4-2a5f-40ec-a1b8-5f3f58a484d2",
   "metadata": {},
   "source": [
    "On commence par lancer yatai via sspcloud, créer un token et se connecter avec la commande suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ece9c-9dfe-4891-bb9a-af48757158d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml login --endpoint <yatai_url> --api-token <token>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39160a0-cd27-4d93-90e0-4b32586e6fc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1- Entrainement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de12da-90bc-4eee-969f-f6f4a8a7d660",
   "metadata": {},
   "source": [
    "Dans ce tutoriel, on va reprendre l'exemple de détecteur de pizza. Un modèle doit être enregisté avec BentoML pour qu'on puisse le déployer avec yatai. Dans ce cas, on a un modèle Pytorch que l'on enregistre sous le bon format en utilisant la fonction (voir `train.py`):\n",
    "````python\n",
    "saved_model = bentoml.pytorch.save_model(\n",
    "    args.model_name,\n",
    "    trained_model,\n",
    "    signatures=signatures,\n",
    "    metadata=metadata,\n",
    "    external_modules=[models],\n",
    ")\n",
    "````\n",
    "- metadata : c'est un dictionnaire qui contient les métadonnées. Dans cet exemple, on enregistre la précision du modèle.\n",
    "- signatures: `signatures = {\"predict\": {\"batchable\": True}}`: les signatures représentent des méthodes implémentées par le modèle et que l'on souhaite utiliser dans l'API. Le paramètre `batchable` indique que la fonction marche sur un lot de données (batch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dfcc30-ef96-43f7-89b1-1f4023e4e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53883bba-7e6e-4ecd-934e-54a9c01aacc6",
   "metadata": {},
   "source": [
    "On peut lister les modèles enregistrés en utilisant l'interface en ligne de commande:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faca94b-2084-4d8e-a55c-2ee7ef06e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml models list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce785abc-eaae-4e7a-be79-23797cd7865d",
   "metadata": {},
   "source": [
    "Yatai offre un dépot centralisé des modèles. Il est configuré pour qu'il enregistre les modèles sur votre bucket S3. Pour exporter et importer des modèles sur yatai, on utilise les commandes: `bentoml models push/pull <model>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26857c-70ca-4d69-bfe8-dc90dd24d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml models push <model_tag>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90205f08-e9a9-4b56-9ebe-6b11a0cb2a7e",
   "metadata": {},
   "source": [
    "**`model_name` est affiché avec la commande `bentoml models list`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc1a14-6c69-44cf-b41b-df2e992a783e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2- Création du service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a3455-29c9-4d05-886d-87e9d123565f",
   "metadata": {
    "tags": []
   },
   "source": [
    "BentoML offre un framework pour créer des API afin de déployer des modèles. \n",
    "Le bloc de base dans bentoml est appelé **service**. Un service bentoml est composé des runners et des APIs. \n",
    "\n",
    "- Runner: Il s'agit de la méthode d'exécuter l'inférence du modèle. Dans `service.py`, on crée un runner pour le modèle avec: `model_runner = bentoml.pytorch.get(\"pytorch\").to_runner()`\n",
    "- APIs: les APIs définissent comment exposer le service. Un service peut avoir un plusieurs APIs. Une API est définie par l'entrée, la sortie et la fonction à exécuter. En décorant une fonction avec `@svc.api`, nous déclarons que la fonction doit être invoquée lorsque cette API est appelée. La fonction API est un endroit idéal pour définir votre logique de service, telle que la récupération de fonctionnalités, le pré et le post-traitement et les inférences de modèle via Runners. En appliquant le service, l'API est transformée en un endpoint HTTP. Dans cet exemple, la fonction `predict_image` sera exposé via le chemin `/predict_image`. On peut aussi spécifier le chemin de la fonction dans le décorateur: `@svc.api(route='/predict')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb45927c-0a0b-48cf-a2b0-a8a990a910cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!bentoml serve service:svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef8464-c9c2-40e7-907c-fd108e38db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -H \"Content-Type: multipart/form-data\" -F'fileobj=@samples/1.jpg;type=image/jpg' localhost:3000/predict_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decd5804-10b7-46fe-b9d2-e64d6940e1ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3- Construction de Bento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9943d92-e89c-4095-97be-b595ef4400b4",
   "metadata": {},
   "source": [
    "Bento est une archive de fichiers avec tout le code source, les modèles, les fichiers de données et les configurations de dépendance nécessaires pour exécuter un bentoml.Service défini par l'utilisateur, emballé dans un format standardisé.\n",
    "\n",
    "Alors que bentoml.Service normalise la définition de l'API d'inférence, y compris la logique de service, l'initialisation des runners et l'entrée de l'API, les types de sortie, Bento standardise la manière de reproduire l'environnement requis pour exécuter un bentoml.Service en production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f54e2-8d43-49b1-b606-fe856ba3f197",
   "metadata": {},
   "source": [
    "Un Bento peut être créé avec la commande CLI `bentoml build` et un fichier de construction `bentofile.yaml`.\n",
    "\n",
    "Le fichier de construction définit les dépendances et le code source nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b0760-ef8a-48f7-ad03-40ec943d566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml build ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3997b-e5d9-45d0-b61f-44dd67247840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!bentoml list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c3863-96a5-49c3-8403-08198d56ee46",
   "metadata": {},
   "source": [
    "On peut exporter le Bento créé à Yatai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc9799a-971f-426d-93d4-4b4b56130499",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml push <bento_name>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96939dd0-1a1f-44a3-856f-ee3c85f7b245",
   "metadata": {},
   "source": [
    "## 4- Déploiement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f508eac-7490-4dd1-a3ef-3dd18c01ccf2",
   "metadata": {},
   "source": [
    "Une fois le Bento est exporté vers Yatai, il est simple de le déployer via l'interface. Dans la rubrique **deployments** de Yatai, on crée un nouveau et on le configure.\n",
    "Ensuite, Yatai Image Builder lance automatiquement un pod pour construire et publier une image Docker qui correspond au Bento, en utilisant `kaniko`. (cette étape pourrait prendre quelques minutes)\n",
    "\n",
    "Enfin, l'image construite est importée et lancée dans un autre \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78369cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b87405",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -H \"Content-Type: multipart/form-data\" -F'fileobj=@samples/1.jpg;type=image/jpg' <service_name>:3000/predict_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
